{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import sys\n",
    "sys.path.append('../resnetunet/')\n",
    "\n",
    "from resnet50_unet import UNetWithResnet50Encoder\n",
    "from utils import BinaryLovaszHingeLoss, DiceLoss, JaccardLoss, dice_coefficient, show_images_and_masks\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fix seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, augment=False, denoise=False):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.denoise = denoise\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "        self.augment = augment\n",
    "\n",
    "        # Updated transformation pipeline for augmented path\n",
    "        self.augment_transform = A.Compose([\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=180, p=0.5),\n",
    "                A.ElasticTransform(alpha=2, sigma=50, alpha_affine=50, p=0.5),\n",
    "            ], p=1.0),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.5),\n",
    "            A.GaussNoise(var_limit=(10, 50), p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomResizedCrop(height=512, width=512, scale=(0.8, 1.0), ratio=(0.75, 1.33), p=0.5),\n",
    "            A.ToFloat(max_value=255.0),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        # Define a simple transformation pipeline for non-augmented path\n",
    "        self.basic_transform = A.Compose([\n",
    "             A.ToFloat(max_value=255.0),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_filename)\n",
    "        mask_path = os.path.join(self.mask_dir, image_filename.replace('image', 'mask'))\n",
    "\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.denoise:\n",
    "            image = cv2.fastNlMeansDenoising(image, None, h=15, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        mask = cv2.resize(mask, (512, 512))\n",
    "        _, mask = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY) \n",
    "\n",
    "\n",
    "        # Stack image to create 3 channels if needed\n",
    "        image = np.stack([image] * 3, axis=-1)\n",
    "\n",
    "        if self.augment:\n",
    "            augmented = self.augment_transform(image=image, mask=mask)\n",
    "        else:\n",
    "            augmented = self.basic_transform(image=image, mask=mask)\n",
    "\n",
    "        image = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return image, mask.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all_encoder_layers(model):\n",
    "    for layer in model.down_blocks:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_block(model, block_name):\n",
    "    \"\"\"\n",
    "    Unfreezes a specific block of the ResNet encoder within the U-Net model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The instance of your UNetWithResnet50Encoder model.\n",
    "    - block_name: A string name of the block to unfreeze (e.g., 'layer4', 'layer3').\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'down_blocks'):\n",
    "        for block in model.down_blocks:\n",
    "            # The down_blocks attribute is a ModuleList; each block is a layer in ResNet\n",
    "            if block_name == block.__class__.__name__:\n",
    "                for param in block.parameters():\n",
    "                    param.requires_grad = True\n",
    "    else:\n",
    "        print(f\"The model does not have the specified block: {block_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "BATCH_SIZE = 4\n",
    "train_dataset = CustomDataset('../data_retina/train/images' , '../data_retina/train/masks', augment=True, denoise=False)\n",
    "val_dataset = CustomDataset('../data_retina/test/images', '../data_retina/test/masks', denoise=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model, Optimizer, and Loss Functions\n",
    "model = UNetWithResnet50Encoder(n_classes=1).to(device)\n",
    "model.load_state_dict(torch.load('output_dir/retina_encoder_l4.pth'))\n",
    "freeze_all_encoder_layers(model)\n",
    "unfreeze_block(model, 'layer4')\n",
    "unfreeze_block(model, 'layer3') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model, (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer_param_groups(model):\n",
    "    encoder_params = []\n",
    "    decoder_params = []\n",
    "    \n",
    "    for block in model.down_blocks:\n",
    "        for param in block.parameters():\n",
    "            if param.requires_grad:\n",
    "                encoder_params.append(param)\n",
    "                \n",
    "\n",
    "    for block in model.up_blocks:\n",
    "        for param in block.parameters():\n",
    "            if param.requires_grad:\n",
    "                decoder_params.append(param)\n",
    "\n",
    "    param_groups = [\n",
    "        {'params': encoder_params, 'lr': 1e-4},  \n",
    "        {'params': decoder_params, 'lr': 1e-4}   \n",
    "    ]\n",
    "    \n",
    "    return param_groups\n",
    "\n",
    "optimizer = torch.optim.AdamW(create_optimizer_param_groups(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "#optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=0.0001)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "loss_fn = DiceLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display train set\n",
    "show_images_and_masks(train_dataset, num_imgs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    loss_total = 0.0\n",
    "    loss_throughout_epoch = []\n",
    "\n",
    "    for input_img, mask in tqdm(train_loader, desc=f'Training epoch {epoch}'):\n",
    "        input_img, mask = input_img.to(device), mask.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_img)\n",
    "        loss = loss_fn(output, mask)\n",
    "\n",
    "        # Combine losses and backpropagate, normalize them against each other\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate individual losses for logging\n",
    "        loss_total += loss.item()\n",
    "        loss_throughout_epoch.append(loss.item())\n",
    "    \n",
    "    # Save graph of loss throughout epoch\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(loss_throughout_epoch, label='Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    if not os.path.exists('output_dir'):\n",
    "        os.makedirs('output_dir')\n",
    "\n",
    "    plt.savefig(f'output_dir/internalloss_graph_epoch_{epoch}.png')\n",
    "    plt.close()\n",
    "\n",
    "    return loss_total / len(train_loader)\n",
    "\n",
    "# Validation Function\n",
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    loss_total = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_img, mask in tqdm(val_loader, desc=f'Validating epoch {epoch}'):\n",
    "            input_img, mask = input_img.to(device), mask.to(device)\n",
    "\n",
    "            output = model(input_img)\n",
    "            loss = loss_fn(output, mask)\n",
    "            loss_total += loss.item()\n",
    "\n",
    "    return loss_total / len(val_loader)\n",
    "\n",
    "\n",
    "# Plot Loss Function\n",
    "def plot_loss(epoch,train_inp_losses, val_inp_losses):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    epochs = range(1, epoch + 2)  \n",
    "\n",
    "    plt.plot(epochs, train_inp_losses, label='Train Loss')\n",
    "    plt.plot(epochs, val_inp_losses, label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output_dir/loss_graph.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Save Model Function\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "train_inp_losses = []\n",
    "val_inp_losses = []\n",
    "\n",
    "best_val_loss = float('inf')  # Initialize with a high value\n",
    "best_model_path = ''  # Path to save the best model\n",
    "\n",
    "\n",
    " \n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_inp_loss = train_one_epoch(epoch) \n",
    "    scheduler.step(train_inp_loss)\n",
    "    val_inp_loss = validate(epoch)  \n",
    "    train_inp_losses.append(train_inp_loss)  \n",
    "    val_inp_losses.append(val_inp_loss)  \n",
    "\n",
    "    # Save model if it has the lowest validation loss so far\n",
    "    if val_inp_loss < best_val_loss:\n",
    "        best_val_loss = val_inp_loss\n",
    "        best_model_path = f'output_dir/best_model.pth'\n",
    "        save_model(model, best_model_path)  \n",
    "\n",
    "    print(f'Epoch {epoch}, Train Loss: {train_inp_loss}, Val Loss: {val_inp_loss}')\n",
    "\n",
    "    # Save model for every epoch (optional if you only want the best model)\n",
    "    #save_model(model, f'st_output_dir/model_epoch_{epoch}.pth')\n",
    "\n",
    "    plot_loss(epoch, train_inp_losses, val_inp_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(image, true_mask=None, predicted_mask=None):\n",
    "    \"\"\"Visualize comparison between input image, true mask, and predicted mask.\"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 10)) \n",
    "\n",
    "    axs[0].imshow(image, cmap='gray')\n",
    "    axs[0].set_title('Input Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    if true_mask is not None:\n",
    "        axs[1].imshow(true_mask, cmap='gray')\n",
    "        axs[1].set_title('True Mask')\n",
    "        axs[1].axis('off')\n",
    "    else:\n",
    "        axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(predicted_mask, cmap='gray')\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_visualize(model, dataset, device, n_images):\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(n_images):\n",
    "            input_img, true_mask = dataset[i]\n",
    "            input_img_unsqueeze = input_img.unsqueeze(0).to(device)\n",
    "\n",
    "            # Predict\n",
    "            pred_mask_logits = model(input_img_unsqueeze)\n",
    "            pred_mask_prob = torch.sigmoid(pred_mask_logits)\n",
    "            pred_mask = pred_mask_prob > 0.5 \n",
    "\n",
    "            # Calculate Dice Coefficient\n",
    "            pred = pred_mask.squeeze()\n",
    "            dice_score = dice_coefficient(pred, true_mask.to(device), smooth=1e-6)\n",
    "\n",
    "            dice_scores.append(dice_score.item())\n",
    "\n",
    "            # Convert for visualization\n",
    "            pred_mask_np = pred_mask.squeeze().cpu().numpy() \n",
    "            input_img_np = input_img.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "            input_img_np = (input_img_np * 255).astype(np.uint8)\n",
    "            true_mask_np = true_mask.squeeze().cpu().numpy() if true_mask is not None else None \n",
    "\n",
    "            visualize(\n",
    "                image=input_img_np, \n",
    "                true_mask=true_mask_np,\n",
    "                predicted_mask=pred_mask_np\n",
    "            )\n",
    "\n",
    "    # Print the average Dice score at the end \n",
    "    average_dice_score = np.mean(dice_scores) \n",
    "    print(f'Average Dice Coefficient over {n_images} images: {average_dice_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset('../data_retina/test/images', '../data_retina/test/masks', augment=False, denoise=False)\n",
    "\n",
    "# Load the model (ensure the model is already trained and weights are loaded)\n",
    "model = UNetWithResnet50Encoder(n_classes=1).to(device)\n",
    "model.load_state_dict(torch.load('output_dir/best_model.pth'))\n",
    "# Predict and visualize on the real data\n",
    "predict_and_visualize(model, test_dataset, device, n_images=len(test_dataset))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
